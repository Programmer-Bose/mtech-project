{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac228d5",
   "metadata": {},
   "source": [
    "### encoding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b11433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def generate_individual(num_tasks, num_robots):\n",
    "    tasks = list(range(num_tasks))\n",
    "    random.shuffle(tasks)\n",
    "\n",
    "    # Evenly distribute tasks (some robots may have 1 more/less)\n",
    "    splits = np.array_split(tasks, num_robots)\n",
    "    return [list(s) for s in splits]\n",
    "\n",
    "# def generate_individual(num_tasks, num_robots):\n",
    "#     tasks = list(range(num_tasks))\n",
    "#     random.shuffle(tasks)\n",
    "\n",
    "#     # Generate random split sizes that sum to num_tasks\n",
    "#     split_sizes = [0] * num_robots\n",
    "#     for _ in range(num_tasks):\n",
    "#         split_sizes[random.randint(0, num_robots - 1)] += 1\n",
    "\n",
    "#     # Distribute tasks accordingly\n",
    "#     individual = []\n",
    "#     index = 0\n",
    "#     for size in split_sizes:\n",
    "#         individual.append(tasks[index:index+size])\n",
    "#         index += size\n",
    "\n",
    "#     return individual\n",
    "\n",
    "\n",
    "def flatten_individual(individual):\n",
    "    \"\"\"Flatten robot-wise task list with -1 as separator\"\"\"\n",
    "    flat = []\n",
    "    for robot_tasks in individual:\n",
    "        flat += robot_tasks + [-1]\n",
    "    return flat[:-1]  # remove last separator\n",
    "\n",
    "def unflatten_individual(flattened):\n",
    "    \"\"\"Convert flattened form back to list-of-lists\"\"\"\n",
    "    robots = []\n",
    "    temp = []\n",
    "    for t in flattened:\n",
    "        if t == -1:\n",
    "            robots.append(temp)\n",
    "            temp = []\n",
    "        else:\n",
    "            temp.append(t)\n",
    "    if temp:\n",
    "        robots.append(temp)\n",
    "    return robots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5c8fd",
   "metadata": {},
   "source": [
    "#### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fc806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Individual: [[9, 16, 0, 14], [7, 3, 12, 11], [5, 6, 18], [13, 10, 15], [17, 4, 8], [1, 19, 2]]\n",
      "Flattened: [9, 16, 0, 14, -1, 7, 3, 12, 11, -1, 5, 6, 18, -1, 13, 10, 15, -1, 17, 4, 8, -1, 1, 19, 2]\n",
      "Restored: [[9, 16, 0, 14], [7, 3, 12, 11], [5, 6, 18], [13, 10, 15], [17, 4, 8], [1, 19, 2]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_tasks = 20\n",
    "    num_robots = 6\n",
    "\n",
    "    individual = generate_individual(num_tasks, num_robots)\n",
    "    print(\"Generated Individual:\", individual)\n",
    "\n",
    "    flat = flatten_individual(individual)\n",
    "    print(\"Flattened:\", flat)\n",
    "\n",
    "    restored = unflatten_individual(flat)\n",
    "    print(\"Restored:\", restored)\n",
    "\n",
    "    assert sorted([t for r in individual for t in r]) == list(range(num_tasks)), \"Missing tasks\"\n",
    "    assert individual == restored, \"Unflatten failed!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72545bd2",
   "metadata": {},
   "source": [
    "### evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e55af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_individual(individual, drl_planner):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        individual: list of task sequences (one per robot)\n",
    "        drl_planner: function(robot_id, task_seq) -> path_length\n",
    "\n",
    "    Returns:\n",
    "        f1 = total path length (sum of all robot paths)\n",
    "        f2 = max path length (time taken to complete all tasks)\n",
    "    \"\"\"\n",
    "    path_lengths = []\n",
    "\n",
    "    for robot_id, task_seq in enumerate(individual):\n",
    "        length = drl_planner(robot_id, task_seq)\n",
    "        path_lengths.append(length)\n",
    "\n",
    "    f1 = sum(path_lengths)\n",
    "    f2 = max(path_lengths)\n",
    "    return f1, f2\n",
    "\n",
    "def fake_drl_planner(robot_id, task_seq):\n",
    "    # Dummy logic: each task adds 10 units of path\n",
    "    return len(task_seq) * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295071b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual: [[13, 9, 18, 16], [3, 11, 5, 4], [14, 12, 7], [10, 6, 19], [15, 17, 8], [2, 0, 1]]\n",
      "Total Path Length (f1): 200\n",
      "Time Taken (f2): 40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # from encoding import generate_individual\n",
    "\n",
    "    ind = generate_individual(num_tasks=20, num_robots=6)\n",
    "    print(\"Individual:\", ind)\n",
    "\n",
    "    f1, f2 = evaluate_individual(ind, fake_drl_planner)\n",
    "    print(\"Total Path Length (f1):\", f1)\n",
    "    print(\"Time Taken (f2):\", f2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d46c3",
   "metadata": {},
   "source": [
    "### clustering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bb6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def cluster_population(flattened_population, num_clusters):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        flattened_population: list of flattened task sequences (1D list with -1 separators)\n",
    "        num_clusters: int, number of clusters for k-means\n",
    "\n",
    "    Returns:\n",
    "        labels: list of cluster IDs for each individual\n",
    "    \"\"\"\n",
    "    # Pad with zeros to equal length for k-means input\n",
    "    max_len = max(len(ind) for ind in flattened_population)\n",
    "    padded = [ind + [0] * (max_len - len(ind)) for ind in flattened_population]\n",
    "\n",
    "    X = np.array(padded)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init='auto', random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d498ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 0: Cluster 1 => [[15, 0, 4, 12], [2, 6, 18, 8], [1, 11, 3], [5, 13, 9], [17, 16, 19], [14, 10, 7]]\n",
      "Individual 1: Cluster 2 => [[4, 0, 16, 12], [14, 7, 8, 13], [15, 2, 11], [3, 17, 6], [10, 18, 9], [1, 5, 19]]\n",
      "Individual 2: Cluster 0 => [[15, 18, 0, 19], [6, 9, 17, 4], [2, 13, 14], [5, 7, 12], [11, 10, 3], [16, 1, 8]]\n",
      "Individual 3: Cluster 0 => [[0, 7, 5, 8], [9, 3, 19, 18], [6, 15, 10], [16, 1, 12], [11, 14, 2], [17, 13, 4]]\n",
      "Individual 4: Cluster 2 => [[13, 2, 14, 18], [17, 16, 6, 19], [9, 15, 4], [10, 5, 8], [11, 1, 3], [0, 7, 12]]\n",
      "Individual 5: Cluster 1 => [[13, 14, 7, 9], [5, 12, 2, 1], [19, 15, 8], [11, 16, 17], [10, 4, 6], [0, 18, 3]]\n",
      "Individual 6: Cluster 2 => [[1, 10, 12, 8], [9, 13, 5, 7], [2, 0, 18], [19, 17, 15], [6, 4, 3], [14, 11, 16]]\n",
      "Individual 7: Cluster 2 => [[5, 12, 3, 15], [2, 17, 4, 7], [14, 1, 9], [6, 8, 18], [16, 11, 19], [10, 0, 13]]\n",
      "Individual 8: Cluster 2 => [[9, 8, 15, 17], [3, 4, 7, 16], [12, 1, 13], [2, 18, 0], [19, 14, 6], [5, 11, 10]]\n",
      "Individual 9: Cluster 1 => [[12, 9, 4, 2], [5, 13, 14, 3], [17, 10, 0], [16, 19, 1], [8, 15, 18], [7, 11, 6]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # from encoding import generate_individual, flatten_individual\n",
    "\n",
    "    num_tasks = 20\n",
    "    num_robots = 6\n",
    "    population_size = 10\n",
    "    population = [generate_individual(num_tasks, num_robots) for _ in range(population_size)]\n",
    "    flat_population = [flatten_individual(ind) for ind in population]\n",
    "\n",
    "    cluster_labels = cluster_population(flat_population, num_clusters=3)\n",
    "\n",
    "    for i, (ind, label) in enumerate(zip(population, cluster_labels)):\n",
    "        print(f\"Individual {i}: Cluster {label} => {ind}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99976ed",
   "metadata": {},
   "source": [
    "### cscd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513a3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    \"\"\"Normalize vectors to [0, 1] range dimension-wise.\"\"\"\n",
    "    array = np.array(vectors, dtype=np.float32)\n",
    "    min_vals = np.min(array, axis=0)\n",
    "    max_vals = np.max(array, axis=0)\n",
    "    denom = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "    return (array - min_vals) / denom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e27de",
   "metadata": {},
   "source": [
    "#### Decision Space Crowding Distance ùê∂ùê∑ùë•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0672b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_decision_space_crowding(flattened_population, cluster_labels):\n",
    "    cluster_map = defaultdict(list)\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        cluster_map[label].append(i)\n",
    "\n",
    "    crowding_x = np.zeros(len(flattened_population))\n",
    "\n",
    "    for cluster_id, indices in cluster_map.items():\n",
    "        if len(indices) <= 2:\n",
    "            # Boundary or singleton cluster ‚Üí assign high crowding\n",
    "            for idx in indices:\n",
    "                crowding_x[idx] = float('inf')\n",
    "            continue\n",
    "\n",
    "        cluster_vectors = [flattened_population[i] for i in indices]\n",
    "        max_len = max(len(v) for v in cluster_vectors)\n",
    "        padded = [v + [0] * (max_len - len(v)) for v in cluster_vectors]\n",
    "        norm_vectors = normalize_vectors(padded)\n",
    "\n",
    "        # Calculate crowding for each dimension\n",
    "        cluster_crowding = np.zeros(len(indices))\n",
    "        for d in range(norm_vectors.shape[1]):\n",
    "            sorted_idx = np.argsort(norm_vectors[:, d])\n",
    "            cluster_crowding[sorted_idx[0]] = float('inf')\n",
    "            cluster_crowding[sorted_idx[-1]] = float('inf')\n",
    "            for j in range(1, len(indices) - 1):\n",
    "                prev_val = norm_vectors[sorted_idx[j - 1], d]\n",
    "                next_val = norm_vectors[sorted_idx[j + 1], d]\n",
    "                cluster_crowding[sorted_idx[j]] += (next_val - prev_val)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            crowding_x[idx] = cluster_crowding[i]\n",
    "\n",
    "    return crowding_x.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2042f8",
   "metadata": {},
   "source": [
    "#### Objective Space Crowding Distance ùê∂ùê∑ùëì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ac27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective_space_crowding(objective_values, front_labels):\n",
    "    front_map = defaultdict(list)\n",
    "    for i, front in enumerate(front_labels):\n",
    "        front_map[front].append(i)\n",
    "\n",
    "    crowding_f = np.zeros(len(objective_values))\n",
    "\n",
    "    for front_id, indices in front_map.items():\n",
    "        if len(indices) <= 2:\n",
    "            for idx in indices:\n",
    "                crowding_f[idx] = float('inf')\n",
    "            continue\n",
    "\n",
    "        front_objs = [objective_values[i] for i in indices]\n",
    "        norm_objs = normalize_vectors(front_objs)\n",
    "\n",
    "        front_crowding = np.zeros(len(indices))\n",
    "        for d in range(norm_objs.shape[1]):\n",
    "            sorted_idx = np.argsort(norm_objs[:, d])\n",
    "            front_crowding[sorted_idx[0]] = float('inf')\n",
    "            front_crowding[sorted_idx[-1]] = float('inf')\n",
    "            for j in range(1, len(indices) - 1):\n",
    "                prev_val = norm_objs[sorted_idx[j - 1], d]\n",
    "                next_val = norm_objs[sorted_idx[j + 1], d]\n",
    "                front_crowding[sorted_idx[j]] += (next_val - prev_val)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            crowding_f[idx] = front_crowding[i]\n",
    "\n",
    "    return crowding_f.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226e132",
   "metadata": {},
   "source": [
    "#### Combine into CSCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5058e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cscd(crowding_x, crowding_f):\n",
    "    finite_cx = [v for v in crowding_x if not np.isinf(v)]\n",
    "    finite_cf = [v for v in crowding_f if not np.isinf(v)]\n",
    "\n",
    "    avg_x = np.mean(finite_cx) if finite_cx else 0\n",
    "    avg_f = np.mean(finite_cf) if finite_cf else 0\n",
    "\n",
    "    cscd = []\n",
    "    for cx, cf in zip(crowding_x, crowding_f):\n",
    "        if cx > avg_x or cf > avg_f:\n",
    "            cscd.append(max(cx, cf))\n",
    "        else:\n",
    "            cscd.append(min(cx, cf))\n",
    "    return cscd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4d655",
   "metadata": {},
   "source": [
    "#### Full Interface: compute_cscd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971c06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cscd_scores(flattened_population, objective_values, cluster_labels, front_labels):\n",
    "    crowding_x = compute_decision_space_crowding(flattened_population, cluster_labels)\n",
    "    crowding_f = compute_objective_space_crowding(objective_values, front_labels)\n",
    "    cscd = compute_cscd(crowding_x, crowding_f)\n",
    "    return cscd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae5789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ind 0: CSCD = inf\n",
      "Ind 1: CSCD = inf\n",
      "Ind 2: CSCD = inf\n",
      "Ind 3: CSCD = inf\n",
      "Ind 4: CSCD = inf\n",
      "Ind 5: CSCD = inf\n",
      "Ind 6: CSCD = inf\n",
      "Ind 7: CSCD = inf\n",
      "Ind 8: CSCD = inf\n",
      "Ind 9: CSCD = inf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # from encoding import generate_individual, flatten_individual\n",
    "\n",
    "    pop_size = 10\n",
    "    num_tasks = 15\n",
    "    num_robots = 3\n",
    "\n",
    "    population = [generate_individual(num_tasks, num_robots) for _ in range(pop_size)]\n",
    "    flat = [flatten_individual(ind) for ind in population]\n",
    "    objectives = [(i, 100 - i) for i in range(pop_size)]  # Dummy values\n",
    "    clusters = [i % 3 for i in range(pop_size)]  # Dummy clusters\n",
    "    fronts = [i // 3 for i in range(pop_size)]   # Dummy fronts\n",
    "\n",
    "    cscd_scores = compute_cscd_scores(flat, objectives, clusters, fronts)\n",
    "    for i, score in enumerate(cscd_scores):\n",
    "        print(f\"Ind {i}: CSCD = {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbf03d",
   "metadata": {},
   "source": [
    "### nsga2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df796ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsga2.py\n",
    "def dominates(a, b):\n",
    "    return all(x <= y for x, y in zip(a, b)) and any(x < y for x, y in zip(a, b))\n",
    "\n",
    "def assign_fronts(objective_values):\n",
    "    N = len(objective_values)\n",
    "    fronts = [None] * N\n",
    "    domination_counts = [0] * N\n",
    "    dominated_sets = [[] for _ in range(N)]\n",
    "    current_front = []\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if dominates(objective_values[i], objective_values[j]):\n",
    "                dominated_sets[i].append(j)\n",
    "            elif dominates(objective_values[j], objective_values[i]):\n",
    "                domination_counts[i] += 1\n",
    "        if domination_counts[i] == 0:\n",
    "            fronts[i] = 0\n",
    "            current_front.append(i)\n",
    "\n",
    "    front = 0\n",
    "    while current_front:\n",
    "        next_front = []\n",
    "        for p in current_front:\n",
    "            for q in dominated_sets[p]:\n",
    "                domination_counts[q] -= 1\n",
    "                if domination_counts[q] == 0:\n",
    "                    fronts[q] = front + 1\n",
    "                    next_front.append(q)\n",
    "        front += 1\n",
    "        current_front = next_front\n",
    "\n",
    "    return fronts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed1a0f",
   "metadata": {},
   "source": [
    "### DBESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f44053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from encoding import unflatten_individual, flatten_individual\n",
    "import random\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    max_len = max(len(a), len(b))\n",
    "    a = a + [0] * (max_len - len(a))\n",
    "    b = b + [0] * (max_len - len(b))\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b88946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_exemplar(index, flattened_pop, front_ranks, cscd_scores, F=0.5):\n",
    "    current_rank = front_ranks[index]\n",
    "    current_vector = flattened_pop[index]\n",
    "\n",
    "    # Step 1: Find candidates from better fronts\n",
    "    candidates = [i for i, r in enumerate(front_ranks) if r < current_rank]\n",
    "\n",
    "    if not candidates:\n",
    "        return index  # fallback: no better fronts\n",
    "\n",
    "    # Step 2: Among those, pick top-CSCD elites (top 50%)\n",
    "    cscd_vals = [cscd_scores[i] for i in candidates]\n",
    "    threshold = np.percentile(cscd_vals, 50)\n",
    "    elites = [i for i in candidates if cscd_scores[i] >= threshold]\n",
    "\n",
    "    if not elites:\n",
    "        elites = candidates  # fallback: use all candidates\n",
    "\n",
    "    # Step 3: Select the closest elite in decision space\n",
    "    distances = [euclidean_distance(current_vector, flattened_pop[i]) for i in elites]\n",
    "    exemplar_idx = elites[np.argmin(distances)]\n",
    "    return exemplar_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8adb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_offspring(parent, exemplar, mutation_prob=0.3):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parent, exemplar: both are list-of-lists task sequences (robot-wise)\n",
    "\n",
    "    Returns:\n",
    "        new_individual: mutated child\n",
    "    \"\"\"\n",
    "    num_robots = len(parent)\n",
    "    tasks = set(t for r in parent for t in r)\n",
    "    \n",
    "    # Flatten exemplar & parent\n",
    "    ex_flat = [t for r in exemplar for t in r]\n",
    "    ex_flat = [t for t in ex_flat if t in tasks]  # ensure same task set\n",
    "\n",
    "    # Crossover: start from exemplar\n",
    "    new_seq = ex_flat.copy()\n",
    "\n",
    "    # Mutation: randomly swap some tasks\n",
    "    if random.random() < mutation_prob:\n",
    "        i, j = random.sample(range(len(new_seq)), 2)\n",
    "        new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "\n",
    "    # Redistribute to robots (uneven split)\n",
    "    splits = [0] * num_robots\n",
    "    for _ in new_seq:\n",
    "        splits[random.randint(0, num_robots - 1)] += 1\n",
    "\n",
    "    robot_seq = []\n",
    "    idx = 0\n",
    "    for s in splits:\n",
    "        robot_seq.append(new_seq[idx:idx+s])\n",
    "        idx += s\n",
    "\n",
    "    return robot_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9e339ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbesm_selection(population, flattened_pop, front_ranks, cscd_scores):\n",
    "    \"\"\"\n",
    "    Returns: new population (offspring) using DBESM logic\n",
    "    \"\"\"\n",
    "    new_pop = []\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        exemplar_idx = select_exemplar(i, flattened_pop, front_ranks, cscd_scores)\n",
    "        exemplar = unflatten_individual(flattened_pop[exemplar_idx])\n",
    "        offspring = generate_offspring(population[i], exemplar)\n",
    "        new_pop.append(offspring)\n",
    "\n",
    "    return new_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eca1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # from encoding import generate_individual, flatten_individual\n",
    "    # from cscd import compute_cscd_scores\n",
    "    # from clustering import cluster_population\n",
    "    # from evaluation import evaluate_individual\n",
    "    # from nsga2 import assign_fronts\n",
    "\n",
    "    pop_size = 50\n",
    "    num_tasks = 20\n",
    "    num_robots = 4\n",
    "    num_clusters = 3\n",
    "\n",
    "    population = [generate_individual(num_tasks, num_robots) for _ in range(pop_size)]\n",
    "    flattened = [flatten_individual(ind) for ind in population]\n",
    "\n",
    "    def fake_drl(r, t): return len(t) * 10\n",
    "    objectives = [evaluate_individual(ind, fake_drl) for ind in population]\n",
    "    clusters = cluster_population(flattened, num_clusters)\n",
    "    fronts = assign_fronts(objectives)\n",
    "    cscd_scores = compute_cscd_scores(flattened, objectives, clusters, fronts)\n",
    "\n",
    "    offspring = dbesm_selection(population, flattened, fronts, cscd_scores)\n",
    "\n",
    "    print(len(offspring[0][0]))  # Should be same as population size\n",
    "    # for i, child in enumerate(offspring):\n",
    "    #     print(f\"Child {i}: {child}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3244aa8",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab3ce3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from encoding import generate_individual, flatten_individual\n",
    "# from evaluation import evaluate_individual\n",
    "# from clustering import cluster_population\n",
    "# from cscd import compute_cscd_scores\n",
    "# from dbesm import dbesm_selection\n",
    "# from nsga2 import assign_fronts\n",
    "# import random\n",
    "\n",
    "def initialize_population(pop_size, num_tasks, num_robots):\n",
    "    return [generate_individual(num_tasks, num_robots) for _ in range(pop_size)]\n",
    "\n",
    "def evaluate_population(population, drl_planner):\n",
    "    return [evaluate_individual(ind, drl_planner) for ind in population]\n",
    "\n",
    "def flatten_population(population):\n",
    "    return [flatten_individual(ind) for ind in population]\n",
    "\n",
    "def select_next_generation(pop, obj_vals, flat, fronts, cscd, N):\n",
    "    \"\"\"\n",
    "    Select top-N individuals based on front + CSCD\n",
    "    \"\"\"\n",
    "    combined = list(zip(pop, obj_vals, flat, fronts, cscd))\n",
    "    combined.sort(key=lambda x: (x[3], -x[4]))  # sort by front asc, CSCD desc\n",
    "    selected = combined[:N]\n",
    "    return [x[0] for x in selected], [x[1] for x in selected]\n",
    "\n",
    "def run_evolution(\n",
    "    num_tasks=9,\n",
    "    num_robots=3,\n",
    "    pop_size=20,\n",
    "    generations=50,\n",
    "    num_clusters=5,\n",
    "    drl_planner=lambda r, s: len(s) * 10  # dummy DRL\n",
    "):\n",
    "    # Step 1: Initialize\n",
    "    population = initialize_population(pop_size, num_tasks, num_robots)\n",
    "\n",
    "    for gen in range(generations):\n",
    "        # print(f\"\\n--- Generation {gen} ---\")\n",
    "\n",
    "        # Step 2: Flatten\n",
    "        flattened = flatten_population(population)\n",
    "\n",
    "        # Step 3: Evaluate\n",
    "        objective_values = evaluate_population(population, drl_planner)\n",
    "\n",
    "        # Step 4: Assign fronts\n",
    "        fronts = assign_fronts(objective_values)\n",
    "\n",
    "        # Step 5: Clustering\n",
    "        clusters = cluster_population(flattened, num_clusters)\n",
    "\n",
    "        # Step 6: CSCD\n",
    "        cscd_scores = compute_cscd_scores(flattened, objective_values, clusters, fronts)\n",
    "\n",
    "        # Step 7: DBESM offspring generation\n",
    "        offspring = dbesm_selection(population, flattened, fronts, cscd_scores)\n",
    "\n",
    "        # Combine populations\n",
    "        combined_population = population + offspring\n",
    "        combined_flattened = flatten_population(combined_population)\n",
    "        combined_objectives = evaluate_population(combined_population, drl_planner)\n",
    "\n",
    "        # Recalculate fronts, clusters, CSCD for selection\n",
    "        combined_fronts = assign_fronts(combined_objectives)\n",
    "        combined_clusters = cluster_population(combined_flattened, num_clusters)\n",
    "        combined_cscd = compute_cscd_scores(combined_flattened, combined_objectives, combined_clusters, combined_fronts)\n",
    "\n",
    "        # Step 8: Select next generation\n",
    "        population, objective_values = select_next_generation(\n",
    "            combined_population,\n",
    "            combined_objectives,\n",
    "            combined_flattened,\n",
    "            combined_fronts,\n",
    "            combined_cscd,\n",
    "            pop_size\n",
    "        )\n",
    "\n",
    "        # Optional: Print best\n",
    "        best = min(objective_values, key=lambda x: (x[0], x[1]))\n",
    "        # print(f\"Best in gen {gen}: f1 = {best[0]}, f2 = {best[1]}\")\n",
    "\n",
    "    return population, objective_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78625f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "h:\\Priyo H\\Study\\JU-IAR\\Research Project\\Unity-ML-Agents\\unity-py\\new_mlag\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Pareto Front (Objective Space):\n",
      "Solution 0: f1 = 190, f2 = 70\n",
      "Solution 1: f1 = 170, f2 = 80\n",
      "Solution 2: f1 = 190, f2 = 70\n",
      "Solution 3: f1 = 170, f2 = 80\n",
      "Solution 4: f1 = 190, f2 = 70\n",
      "Solution 5: f1 = 190, f2 = 70\n",
      "Solution 6: f1 = 170, f2 = 90\n",
      "Solution 7: f1 = 180, f2 = 80\n",
      "Solution 8: f1 = 170, f2 = 90\n",
      "Solution 9: f1 = 180, f2 = 80\n",
      "Solution 10: f1 = 180, f2 = 80\n",
      "Solution 11: f1 = 180, f2 = 80\n",
      "Solution 12: f1 = 200, f2 = 80\n",
      "Solution 13: f1 = 200, f2 = 80\n",
      "Solution 14: f1 = 200, f2 = 80\n",
      "Solution 15: f1 = 190, f2 = 90\n",
      "Solution 16: f1 = 190, f2 = 90\n",
      "Solution 17: f1 = 190, f2 = 90\n",
      "Solution 18: f1 = 200, f2 = 80\n",
      "Solution 19: f1 = 200, f2 = 80\n",
      "\n",
      "Final Pareto Set (Decision Space):\n",
      "Solution 0:\n",
      "  Robot 1: [11, 5, 8, 10, 7, 6, 9]\n",
      "  Robot 2: [3, 0, 1]\n",
      "  Robot 3: [2, 4]\n",
      "Solution 1:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8, 7]\n",
      "  Robot 2: [5, 4, 9]\n",
      "  Robot 3: [1]\n",
      "Solution 2:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8]\n",
      "  Robot 2: [7, 5, 4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 3:\n",
      "  Robot 1: [11, 5, 8, 10, 7, 6, 9, 3]\n",
      "  Robot 2: [0, 1, 2]\n",
      "  Robot 3: [4]\n",
      "Solution 4:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8]\n",
      "  Robot 2: [7, 5, 4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 5:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8]\n",
      "  Robot 2: [7, 5, 4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 6:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8, 7, 5]\n",
      "  Robot 2: [4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 7:\n",
      "  Robot 1: [11, 5, 8, 10, 7, 6, 9, 3]\n",
      "  Robot 2: [0, 1]\n",
      "  Robot 3: [2, 4]\n",
      "Solution 8:\n",
      "  Robot 1: [11, 5, 8, 10, 7, 6, 9, 3, 0]\n",
      "  Robot 2: [1]\n",
      "  Robot 3: [2, 4]\n",
      "Solution 9:\n",
      "  Robot 1: [11, 6, 10, 2, 3, 0, 8]\n",
      "  Robot 2: [7, 5, 4, 9]\n",
      "  Robot 3: [1]\n",
      "Solution 10:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8]\n",
      "  Robot 2: [7, 5, 4, 9]\n",
      "  Robot 3: [1]\n",
      "Solution 11:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8]\n",
      "  Robot 2: [7, 5, 4, 9]\n",
      "  Robot 3: [1]\n",
      "Solution 12:\n",
      "  Robot 1: [0, 10, 3, 6, 4, 9]\n",
      "  Robot 2: [8, 2, 11, 7]\n",
      "  Robot 3: [5, 1]\n",
      "Solution 13:\n",
      "  Robot 1: [11, 5, 4, 10, 7, 6]\n",
      "  Robot 2: [9, 3, 0, 1]\n",
      "  Robot 3: [2, 8]\n",
      "Solution 14:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0]\n",
      "  Robot 2: [8, 7, 5, 4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 15:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8, 7]\n",
      "  Robot 2: [5]\n",
      "  Robot 3: [4, 9, 1]\n",
      "Solution 16:\n",
      "  Robot 1: [7, 5, 8, 10, 11, 6, 9, 3]\n",
      "  Robot 2: [0]\n",
      "  Robot 3: [1, 2, 4]\n",
      "Solution 17:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0, 8, 7]\n",
      "  Robot 2: [5]\n",
      "  Robot 3: [4, 9, 1]\n",
      "Solution 18:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0]\n",
      "  Robot 2: [8, 7, 5, 4]\n",
      "  Robot 3: [9, 1]\n",
      "Solution 19:\n",
      "  Robot 1: [11, 6, 3, 2, 10, 0]\n",
      "  Robot 2: [8, 7, 5, 4]\n",
      "  Robot 3: [9, 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    final_pop, final_objs = run_evolution(\n",
    "        num_tasks=12,\n",
    "        num_robots=3,\n",
    "        pop_size=20,\n",
    "        generations=20,\n",
    "        num_clusters=4,\n",
    "        drl_planner=lambda r, s: len(s) * (r + 1) * 10  # Fake but variable\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal Pareto Front (Objective Space):\")\n",
    "    for i, obj in enumerate(final_objs):\n",
    "        print(f\"Solution {i}: f1 = {obj[0]}, f2 = {obj[1]}\")\n",
    "\n",
    "    print(\"\\nFinal Pareto Set (Decision Space):\")\n",
    "    for i, individual in enumerate(final_pop):\n",
    "        print(f\"Solution {i}:\")\n",
    "        for r, tasks in enumerate(individual):\n",
    "            print(f\"  Robot {r+1}: {tasks}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_mlag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
